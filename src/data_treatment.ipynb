{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"orig_nbformat":2,"kernelspec":{"name":"Python 3.7.4 64-bit ('base': conda)","display_name":"Python 3.7.4 64-bit ('base': conda)","metadata":{"interpreter":{"hash":"4fca0eae666ee8a363f6e42c2ce25cbdba496d9098d60dd72f409fa19626efc9"}}},"colab":{"name":"data_treatment.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5076f2f6485f42c59b6ed62b4196dd8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b9f5843baf34c209ca7f5f8c8282f61","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_62c849c2a6e74c4cbe3306943ac8c3a0","IPY_MODEL_e4d6eb9d652b4050850664641b4075bd"]}},"1b9f5843baf34c209ca7f5f8c8282f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62c849c2a6e74c4cbe3306943ac8c3a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8494e4995e6c4970acf2354ccca2ca3a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed1500a459244efcab8e18110e1c2617"}},"e4d6eb9d652b4050850664641b4075bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4f3d380c2f2242518e88d7655a15650d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 806kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ded062e401124662bfd1a3d970826963"}},"8494e4995e6c4970acf2354ccca2ca3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ed1500a459244efcab8e18110e1c2617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f3d380c2f2242518e88d7655a15650d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ded062e401124662bfd1a3d970826963":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de0650efcc304715948f804e920b3a8c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6e7e55cfb0a342d099c9aaf351881431","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_22e6a140b8bf4bfc849cdde37be0465a","IPY_MODEL_64ee599127e04e96981e1d2df1f9b9c7"]}},"6e7e55cfb0a342d099c9aaf351881431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22e6a140b8bf4bfc849cdde37be0465a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_edf1e9289dc14c41ba155c5d33f3c065","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6372721fc9d6491ba4e9d36a4f2a98ee"}},"64ee599127e04e96981e1d2df1f9b9c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a11f02fdd71b47fc9d8a4820083f72ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 1.51kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e80628e7aad948bd95b00326edfd935f"}},"edf1e9289dc14c41ba155c5d33f3c065":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6372721fc9d6491ba4e9d36a4f2a98ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a11f02fdd71b47fc9d8a4820083f72ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e80628e7aad948bd95b00326edfd935f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7dd838f0004d43fcaf16822cf53210a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_17d288e6e4e4475386f0f6db9343a0ef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dc5b862adc894e9b9b4b1c0a50c0d61f","IPY_MODEL_5a4cce0ad89547be8a9722ef24eee956"]}},"17d288e6e4e4475386f0f6db9343a0ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc5b862adc894e9b9b4b1c0a50c0d61f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b61e83c9577c4b32951ba74747dcfd51","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d100185f7914209a75a2bd87636abdd"}},"5a4cce0ad89547be8a9722ef24eee956":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c8d04175bffa4f12a7deffa97122785a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:23&lt;00:00, 18.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da075ff84d594f8dbcd9839e294c6c1f"}},"b61e83c9577c4b32951ba74747dcfd51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1d100185f7914209a75a2bd87636abdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8d04175bffa4f12a7deffa97122785a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"da075ff84d594f8dbcd9839e294c6c1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"gO-Rd2SgDFRa","executionInfo":{"status":"ok","timestamp":1602271132075,"user_tz":-120,"elapsed":6470,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"63898b5e-d79c-4608-8cb3-0fc6725ade43","colab":{"base_uri":"https://localhost:8080/","height":629}},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 29.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 40.5MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=1597768b9f8e01b3b4bbc1a808af6872085a51ea567aedcde806c86908131fc9\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dx-8cc0XCCvu","executionInfo":{"status":"ok","timestamp":1602271137725,"user_tz":-120,"elapsed":11982,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n","import random\n","from transformers import BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n","import time\n","import datetime\n","#import logging\n","#import matplotlib.pyplot as plt\n","#import seaborn as sns\n","#from sklearn.model_selection import train_test_split\n","# keras.preprocessing.sequence import pad_sequences\n","#from torch.utilis.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n","#import time"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zqZEpPtCPBB","executionInfo":{"status":"ok","timestamp":1602271194755,"user_tz":-120,"elapsed":68930,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"32463652-dfdb-4065-e847-00aa793b28bc","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0PjdOpTcEQ74","executionInfo":{"status":"ok","timestamp":1602271194791,"user_tz":-120,"elapsed":68876,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"167e5e54-369f-4c0d-ccb4-50f15e4cf43c","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","  print(\"there are %d GPU(s) available.\" % torch.cuda.device_count())\n","  print(\"The GPU used in this code is: \", torch.cuda.get_device_name(0))\n","else:\n","  assert False, \"No GPU detected. Please, select GPU in the Colab.\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["there are 1 GPU(s) available.\n","The GPU used in this code is:  Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U7fwoziICCvx","executionInfo":{"status":"ok","timestamp":1602271194799,"user_tz":-120,"elapsed":68802,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["df = pd.read_csv(\"/content/drive/My Drive/Disaster-Or-Not/data/train.csv\", delimiter=\",\", header=0, names=[\"id\", \"keyword\", \"location\", \"text\",\"target\"])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"0151Ljf6CCv0","executionInfo":{"status":"ok","timestamp":1602271194804,"user_tz":-120,"elapsed":68725,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"3ffa398e-4c33-40a3-d545-dfef8ecb2548","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head(5)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id keyword  ...                                               text target\n","0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n","1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n","2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n","3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n","4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"tags":[],"id":"jG4p4o5ECCv3","executionInfo":{"status":"ok","timestamp":1602271195518,"user_tz":-120,"elapsed":69349,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"f712a61b-0244-486f-d833-7107a07b52f9","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(\"dimensions of training data:\", df.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["dimensions of training data: (7613, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"tags":[],"id":"gIp8iUGKCCv6","executionInfo":{"status":"ok","timestamp":1602271195525,"user_tz":-120,"elapsed":69251,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"a38fd1ea-fa0c-4b0b-9824-6c706dc025ff","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(\"the number of sentences seen as disaster telling:\", df[df.target==1].shape[0])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["the number of sentences seen as disaster telling: 3271\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"tags":[],"id":"vB10_in4CCv9","executionInfo":{"status":"ok","timestamp":1602271195533,"user_tz":-120,"elapsed":69171,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"ae55f917-a4a9-4938-ae90-92c0762e107e","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(\"the number of observations of keyword == naN is:\",df[pd.isna(df.keyword)].shape[0])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["the number of observations of keyword == naN is: 61\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sS6D3pVbCCwA","executionInfo":{"status":"ok","timestamp":1602271195541,"user_tz":-120,"elapsed":69084,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"d0cc57d4-e354-4ee2-dcc2-cb399969eb42","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df[df.target == 1].sample(5)[['text']]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7041</th>\n","      <td>Obama Declares Disaster for Typhoon-Devastated...</td>\n","    </tr>\n","    <tr>\n","      <th>7253</th>\n","      <td>'The Reagan Administration had arranged for Is...</td>\n","    </tr>\n","    <tr>\n","      <th>7435</th>\n","      <td>Gunshot wound #9 is in the bicep. The only one...</td>\n","    </tr>\n","    <tr>\n","      <th>1187</th>\n","      <td>Ashes 2015: Australia collapse at Trent Bridge...</td>\n","    </tr>\n","    <tr>\n","      <th>4658</th>\n","      <td>This is set to become a huge one month wonder....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   text\n","7041  Obama Declares Disaster for Typhoon-Devastated...\n","7253  'The Reagan Administration had arranged for Is...\n","7435  Gunshot wound #9 is in the bicep. The only one...\n","1187  Ashes 2015: Australia collapse at Trent Bridge...\n","4658  This is set to become a huge one month wonder...."]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"CmMxZK9RCCwD","executionInfo":{"status":"ok","timestamp":1602271195547,"user_tz":-120,"elapsed":69000,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["texts = df.text.values\n","targets = df.target.values"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"JhI07KXwCCwG","executionInfo":{"status":"ok","timestamp":1602271196136,"user_tz":-120,"elapsed":69509,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"4f4596b4-647d-4b66-daff-88dd3123685c","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["5076f2f6485f42c59b6ed62b4196dd8d","1b9f5843baf34c209ca7f5f8c8282f61","62c849c2a6e74c4cbe3306943ac8c3a0","e4d6eb9d652b4050850664641b4075bd","8494e4995e6c4970acf2354ccca2ca3a","ed1500a459244efcab8e18110e1c2617","4f3d380c2f2242518e88d7655a15650d","ded062e401124662bfd1a3d970826963"]}},"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5076f2f6485f42c59b6ed62b4196dd8d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"tags":[],"id":"QNwe5RkZCCwJ","executionInfo":{"status":"ok","timestamp":1602271196142,"user_tz":-120,"elapsed":69444,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"1438c46c-9aae-4872-9b53-164eb78570fc","colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["print(texts[150])\n","print(tokenizer.tokenize(texts[150]))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["@mickinyman @TheAtlantic That or they might be killed in an airplane accident in the night a car wreck! Politics at it's best.\n","['@', 'mick', '##iny', '##man', '@', 'the', '##at', '##lan', '##tic', 'that', 'or', 'they', 'might', 'be', 'killed', 'in', 'an', 'airplane', 'accident', 'in', 'the', 'night', 'a', 'car', 'wreck', '!', 'politics', 'at', 'it', \"'\", 's', 'best', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"tags":[],"id":"aarq62KhCCwL","executionInfo":{"status":"ok","timestamp":1602271199115,"user_tz":-120,"elapsed":72339,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"4cf4fb4e-31e9-40f1-bd84-b99e9595ecbd","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["max_len = 0\n","\n","for text in texts:\n","    input_ids = tokenizer.encode(text, add_special_tokens=True)\n","    max_len = max(max_len,len(input_ids))\n","print(\"max length to set to is\", max_len)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["max length to set to is 84\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0UnLJeTSCCwO","executionInfo":{"status":"ok","timestamp":1602271202387,"user_tz":-120,"elapsed":75530,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"cc98545f-c3f5-4140-a61e-ddbc5a0225cc","colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["input_ids = []\n","attention_masks = []\n","\n","for text in texts:\n","    encoded_dict = tokenizer.encode_plus(text, add_special_tokens=True, max_length=84, truncation=True, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids,dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","targets = torch.tensor(targets)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"tags":[],"id":"Ol-qbDMkCCwR","executionInfo":{"status":"ok","timestamp":1602271202404,"user_tz":-120,"elapsed":75466,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["dataset = TensorDataset(input_ids, attention_masks, targets)\n","\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset)-train_size\n","\n","random.seed(10)\n","train_dataset, val_dataset = random_split(dataset,[train_size,val_size])"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsD4ShpSCCwU","executionInfo":{"status":"ok","timestamp":1602271202409,"user_tz":-120,"elapsed":75403,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["\n","batch_size = 32\n","\n","train_data_loader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size= batch_size)\n","validation_data_loader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"Wg6S2kI2CCwW","executionInfo":{"status":"ok","timestamp":1602271226605,"user_tz":-120,"elapsed":99530,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"9418c201-8df4-4f9d-ba25-f89230ff928c","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["de0650efcc304715948f804e920b3a8c","6e7e55cfb0a342d099c9aaf351881431","22e6a140b8bf4bfc849cdde37be0465a","64ee599127e04e96981e1d2df1f9b9c7","edf1e9289dc14c41ba155c5d33f3c065","6372721fc9d6491ba4e9d36a4f2a98ee","a11f02fdd71b47fc9d8a4820083f72ae","e80628e7aad948bd95b00326edfd935f","7dd838f0004d43fcaf16822cf53210a8","17d288e6e4e4475386f0f6db9343a0ef","dc5b862adc894e9b9b4b1c0a50c0d61f","5a4cce0ad89547be8a9722ef24eee956","b61e83c9577c4b32951ba74747dcfd51","1d100185f7914209a75a2bd87636abdd","c8d04175bffa4f12a7deffa97122785a","da075ff84d594f8dbcd9839e294c6c1f"]}},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 2, output_attentions = False, output_hidden_states = False)\n","\n","model.cuda()"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de0650efcc304715948f804e920b3a8c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dd838f0004d43fcaf16822cf53210a8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"K1YLrTodCCwZ","executionInfo":{"status":"ok","timestamp":1602271226611,"user_tz":-120,"elapsed":99449,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n","epochs = 4\n","\n","total_steps = len(train_data_loader)*epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0, num_training_steps = total_steps)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"Di4CqlbwCCwb","executionInfo":{"status":"ok","timestamp":1602271226616,"user_tz":-120,"elapsed":99384,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["def flat_accuracy (preds, labels):\n","    pred_flat = np.argmax(preds, axis = 1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat)/len(labels_flat)\n","\n","def format_time(elapsed):\n","    return str(datetime.timedelta(seconds=int(round(elapsed))))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jSIxc9LHfDJ","executionInfo":{"status":"ok","timestamp":1602271643137,"user_tz":-120,"elapsed":515842,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"ec67a0a7-0ce9-4018-db0e-3fd834d06680","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","\n","random.seed(32)\n","np.random.seed(32)\n","torch.manual_seed(32)\n","\n","\n","#Storing training stats\n","training_stats = []\n","\n","total_t0 = time.time()\n","\n","\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print(\"================ Epoch {:} / {:} ================\".format(epoch_i + 1, epochs))\n","    print('Training ongoing...')\n","\n","    t0 = time.time()\n","\n","    #reseting total loss for current epoch\n","    total_train_loss = 0\n","\n","    #Activating train mode\n","    model.train\n","\n","    for step, batch in enumerate(train_data_loader):\n","        \n","        # Progress visualization every 15 batches\n","        if step % 15 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print(' Batch {: >5,} of {:>5,}.  Elapsed: {:}.'.format(step, len(train_data_loader), elapsed))\n","        \n","        # Unpacking batches\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        #Clear Grads\n","        model.zero_grad()\n","\n","        #performing forward pass\n","        loss, loggits = model(b_input_ids, token_type_ids = None, attention_mask = b_input_mask, labels= b_labels)\n","\n","        #Accumulating training loss\n","        total_train_loss += loss.item()\n","\n","        # Performing Backward pass\n","        loss.backward()\n","\n","        # Setting the norm of gradients to 1.0.\n","        torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n","\n","        #Updating parameters\n","        optimizer.step()\n","\n","        #Updating the learning rate\n","        scheduler.step()\n","\n","    avg_train_loss = total_train_loss / len(train_data_loader)\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\" Avg training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\" Training epoch took: {:}\".format(training_time)) \n","\n","    print(\"Running validation\")\n","\n","    t0 = time.time()\n","\n","    model.eval()\n","\n","\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    for batch in validation_data_loader:\n","\n","      b_input_ids = batch[0].to(device)\n","      b_input_mask = batch[1].to(device)\n","      b_labels = batch[2].to(device)\n","\n","      with torch.no_grad():\n","\n","        (loss, logits) = model(b_input_ids,token_type_ids = None, attention_mask = b_input_mask, labels = b_labels)\n","\n","      total_eval_loss += loss.item()\n","\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = b_labels.to('cpu').numpy()\n","\n","      total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","    print(\"validation Over\")\n","\n","    avg_val_accuracy = total_eval_accuracy/len(validation_data_loader)\n","    avg_val_loss = total_eval_loss/len(validation_data_loader)\n","    validation_time = format_time(time.time()-t0)\n","\n","    print(\" Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    print(\" Validation Loss {0:.2f}\".format(avg_val_loss))\n","    print(\" Validation took: {:}\".format(validation_time))\n","\n","    training_stats.append({\"epoch\": epoch_i + 1,\n","                         \"training_loss\": avg_train_loss,\n","                         \"val_loss\": avg_val_loss,\n","                         \"val_accuracy\": avg_val_accuracy,\n","                         \"training_time\": training_time,\n","                         \"validation_time\": validation_time\n","                         })\n","\n","print(\"Training Over!!!!\")\n","print(\"it took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["\n","================ Epoch 1 / 4 ================\n","Training ongoing...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"],"name":"stderr"},{"output_type":"stream","text":[" Batch    15 of   215.  Elapsed: 0:00:07.\n"," Batch    30 of   215.  Elapsed: 0:00:13.\n"," Batch    45 of   215.  Elapsed: 0:00:20.\n"," Batch    60 of   215.  Elapsed: 0:00:26.\n"," Batch    75 of   215.  Elapsed: 0:00:33.\n"," Batch    90 of   215.  Elapsed: 0:00:40.\n"," Batch   105 of   215.  Elapsed: 0:00:46.\n"," Batch   120 of   215.  Elapsed: 0:00:53.\n"," Batch   135 of   215.  Elapsed: 0:01:00.\n"," Batch   150 of   215.  Elapsed: 0:01:07.\n"," Batch   165 of   215.  Elapsed: 0:01:14.\n"," Batch   180 of   215.  Elapsed: 0:01:21.\n"," Batch   195 of   215.  Elapsed: 0:01:28.\n"," Batch   210 of   215.  Elapsed: 0:01:36.\n","\n"," Avg training loss: 0.44\n"," Training epoch took: 0:01:38\n","Running validation\n","validation Over\n"," Accuracy: 0.84\n"," Validation Loss 0.39\n"," Validation took: 0:00:04\n","\n","================ Epoch 2 / 4 ================\n","Training ongoing...\n"," Batch    15 of   215.  Elapsed: 0:00:07.\n"," Batch    30 of   215.  Elapsed: 0:00:14.\n"," Batch    45 of   215.  Elapsed: 0:00:21.\n"," Batch    60 of   215.  Elapsed: 0:00:28.\n"," Batch    75 of   215.  Elapsed: 0:00:35.\n"," Batch    90 of   215.  Elapsed: 0:00:42.\n"," Batch   105 of   215.  Elapsed: 0:00:49.\n"," Batch   120 of   215.  Elapsed: 0:00:56.\n"," Batch   135 of   215.  Elapsed: 0:01:03.\n"," Batch   150 of   215.  Elapsed: 0:01:11.\n"," Batch   165 of   215.  Elapsed: 0:01:18.\n"," Batch   180 of   215.  Elapsed: 0:01:25.\n"," Batch   195 of   215.  Elapsed: 0:01:32.\n"," Batch   210 of   215.  Elapsed: 0:01:39.\n","\n"," Avg training loss: 0.27\n"," Training epoch took: 0:01:41\n","Running validation\n","validation Over\n"," Accuracy: 0.82\n"," Validation Loss 0.41\n"," Validation took: 0:00:04\n","\n","================ Epoch 3 / 4 ================\n","Training ongoing...\n"," Batch    15 of   215.  Elapsed: 0:00:07.\n"," Batch    30 of   215.  Elapsed: 0:00:14.\n"," Batch    45 of   215.  Elapsed: 0:00:21.\n"," Batch    60 of   215.  Elapsed: 0:00:28.\n"," Batch    75 of   215.  Elapsed: 0:00:35.\n"," Batch    90 of   215.  Elapsed: 0:00:42.\n"," Batch   105 of   215.  Elapsed: 0:00:49.\n"," Batch   120 of   215.  Elapsed: 0:00:56.\n"," Batch   135 of   215.  Elapsed: 0:01:04.\n"," Batch   150 of   215.  Elapsed: 0:01:11.\n"," Batch   165 of   215.  Elapsed: 0:01:18.\n"," Batch   180 of   215.  Elapsed: 0:01:25.\n"," Batch   195 of   215.  Elapsed: 0:01:32.\n"," Batch   210 of   215.  Elapsed: 0:01:39.\n","\n"," Avg training loss: 0.15\n"," Training epoch took: 0:01:41\n","Running validation\n","validation Over\n"," Accuracy: 0.83\n"," Validation Loss 0.48\n"," Validation took: 0:00:04\n","\n","================ Epoch 4 / 4 ================\n","Training ongoing...\n"," Batch    15 of   215.  Elapsed: 0:00:07.\n"," Batch    30 of   215.  Elapsed: 0:00:14.\n"," Batch    45 of   215.  Elapsed: 0:00:21.\n"," Batch    60 of   215.  Elapsed: 0:00:28.\n"," Batch    75 of   215.  Elapsed: 0:00:35.\n"," Batch    90 of   215.  Elapsed: 0:00:42.\n"," Batch   105 of   215.  Elapsed: 0:00:49.\n"," Batch   120 of   215.  Elapsed: 0:00:57.\n"," Batch   135 of   215.  Elapsed: 0:01:04.\n"," Batch   150 of   215.  Elapsed: 0:01:11.\n"," Batch   165 of   215.  Elapsed: 0:01:18.\n"," Batch   180 of   215.  Elapsed: 0:01:25.\n"," Batch   195 of   215.  Elapsed: 0:01:32.\n"," Batch   210 of   215.  Elapsed: 0:01:39.\n","\n"," Avg training loss: 0.09\n"," Training epoch took: 0:01:41\n","Running validation\n","validation Over\n"," Accuracy: 0.82\n"," Validation Loss 0.58\n"," Validation took: 0:00:04\n","Training Over!!!!\n","it took 0:06:57 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wODNrDhias5w"},"source":["Dealing with test data set now"]},{"cell_type":"code","metadata":{"id":"k0q2wm4sa2k8","executionInfo":{"status":"ok","timestamp":1602271643145,"user_tz":-120,"elapsed":515772,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["testdata = pd.read_csv(\"/content/drive/My Drive/Disaster-Or-Not/data/test.csv\", delimiter=\",\", header=0, names=[\"id\", \"keyword\", \"location\", \"text\"])"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKZv3d9VcA9N","executionInfo":{"status":"ok","timestamp":1602271643151,"user_tz":-120,"elapsed":515707,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["test_texts = testdata.text.values"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qr2IY7vKkkji","executionInfo":{"status":"ok","timestamp":1602271644767,"user_tz":-120,"elapsed":517257,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"aa6f031a-bd6b-453d-b874-ff7ca248fdda","colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["test_input_ids = []\n","test_attention_masks = []\n","\n","for text in test_texts: \n","  test_encoded_dict = tokenizer.encode_plus(text, add_special_tokens=True, max_length=84, truncation=True, pad_to_max_length = True, return_attention_mask = True, return_tensors='pt')\n","  test_input_ids.append(test_encoded_dict['input_ids'])\n","  test_attention_masks.append(test_encoded_dict['attention_mask'])\n","\n","test_input_ids = torch.cat(test_input_ids, dim=0)\n","test_attention_masks = torch.cat(test_attention_masks, dim=0)\n","print(\"yo\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["yo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SMVuNXpe1plu","executionInfo":{"status":"ok","timestamp":1602272031825,"user_tz":-120,"elapsed":927,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["test_real_data = TensorDataset(test_input_ids, test_attention_masks)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"wErCysHkl5Ag","executionInfo":{"status":"ok","timestamp":1602272367287,"user_tz":-120,"elapsed":817,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}}},"source":["test_data_loader = DataLoader(test_real_data, sampler = SequentialSampler(testdata), batch_size= batch_size)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-RwSJp023vO","executionInfo":{"status":"ok","timestamp":1602275887659,"user_tz":-120,"elapsed":18133,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"0b5baf3e-e62f-4e8a-dc82-45db23971cc0","colab":{"base_uri":"https://localhost:8080/","height":899}},"source":["model.eval()\n","\n","preds = []\n","for step, batch in enumerate(test_data_loader):\n","\n","  if step % 6 == 0 and not step == 0:\n","    print(f\"==============================Batch {step} out of {len(test_data_loader)} =========================\")\n","    print(\"\\n\")\n","\n","  b_test_input_ids = batch[0].to(device)\n","  b_test_input_masks = batch[1].to(device)\n","\n","  with torch.no_grad():\n","    outputs = model(b_test_input_ids, token_type_ids=None, attention_mask=b_test_input_masks)\n","    logits = outputs[0]\n","    logits = logits.detach().cpu().numpy()\n","    logits = np.argmax(logits, axis=1).flatten()\n","    preds.append(logits)\n","\n","preds = [element for my_list in preds for element in my_list]\n","\n","print(\"Outputs released. OVER!!\")"],"execution_count":49,"outputs":[{"output_type":"stream","text":["==============================Batch 6 out of 102 =========================\n","\n","\n","==============================Batch 12 out of 102 =========================\n","\n","\n","==============================Batch 18 out of 102 =========================\n","\n","\n","==============================Batch 24 out of 102 =========================\n","\n","\n","==============================Batch 30 out of 102 =========================\n","\n","\n","==============================Batch 36 out of 102 =========================\n","\n","\n","==============================Batch 42 out of 102 =========================\n","\n","\n","==============================Batch 48 out of 102 =========================\n","\n","\n","==============================Batch 54 out of 102 =========================\n","\n","\n","==============================Batch 60 out of 102 =========================\n","\n","\n","==============================Batch 66 out of 102 =========================\n","\n","\n","==============================Batch 72 out of 102 =========================\n","\n","\n","==============================Batch 78 out of 102 =========================\n","\n","\n","==============================Batch 84 out of 102 =========================\n","\n","\n","==============================Batch 90 out of 102 =========================\n","\n","\n","==============================Batch 96 out of 102 =========================\n","\n","\n","Outputs released. OVER!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e6xllJQwcxRv","executionInfo":{"status":"error","timestamp":1602327606831,"user_tz":-120,"elapsed":1140,"user":{"displayName":"djiwesh ahh","photoUrl":"","userId":"07520581437628537732"}},"outputId":"99768ccf-6973-46bb-926c-95aaa612b54f","colab":{"base_uri":"https://localhost:8080/","height":208}},"source":["output = pd.DataFrame( {'id': testdata.id, 'target': preds})\n","output.to_csv ('/content/drive/My Drive/Disaster-Or-Not/data/my_submission.csv', index=False)\n","print(\"Submission file successfully saved!\")"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0125ee4157ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Disaster-Or-Not/data/my_submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Submission file successfully saved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]}]}